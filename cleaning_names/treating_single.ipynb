{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carol Erthal\\AppData\\Local\\Temp\\ipykernel_14500\\2494190213.py:8: DtypeWarning: Columns (8,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Banco de Súmulas - Sumulas.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "import re\n",
    "import unidecode \n",
    "\n",
    "data = pd.read_csv('Banco de Súmulas - Sumulas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carol Erthal\\AppData\\Local\\Temp\\ipykernel_14500\\2066453530.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Nome Competidor'] = data['Nome Competidor'].str.upper()\n",
      "C:\\Users\\Carol Erthal\\AppData\\Local\\Temp\\ipykernel_14500\\2066453530.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Nome Competidor'] = data['Nome Competidor'].apply(unidecode.unidecode)\n",
      "C:\\Users\\Carol Erthal\\AppData\\Local\\Temp\\ipykernel_14500\\2066453530.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Nome Competidor'] = data['Nome Competidor'].str.replace('  ', ' ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only single classes\n",
    "# classes = ['IQFOIL Fem.', 'Formula Kite Fem.', 'IQFOIL Masc.','Formula Kite Masc.', 'Ilca 7', 'Ilca 6']\n",
    "classes = ['IQFOIL Fem.', 'Formula Kite Fem.', 'IQFOIL Masc.','Formula Kite Masc.']\n",
    "data = data[data['Classe Vela'].isin(classes)]\n",
    "\n",
    "# upper case all \"Nome Competidor\" \n",
    "data['Nome Competidor'] = data['Nome Competidor'].str.upper()\n",
    "\n",
    "# unidecode all \"Nome Competidor\"\n",
    "data['Nome Competidor'] = data['Nome Competidor'].apply(unidecode.unidecode)\n",
    "\n",
    "# replace double spaces with single space\n",
    "data['Nome Competidor'] = data['Nome Competidor'].str.replace(r'\\s+', ' ')\n",
    "\n",
    "# get unique names\n",
    "names = data['Nome Competidor'].unique()\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix mixed up names function\n",
    "def are_names_same(str1, str2):\n",
    "    # Split the strings into words, remove spaces, and sort the lists of words\n",
    "    name1 = sorted(str1.split())\n",
    "    name2 = sorted(str2.split())\n",
    "    \n",
    "    # Check if the sorted lists of words are equal\n",
    "    return name1 == name2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy names to a list\n",
    "names_list = names.tolist()\n",
    "\n",
    "# create a list with people with mixed up names, adding each pair as a sublist\n",
    "mixed_up_names = []\n",
    "for name1 in names_list:\n",
    "    for name2 in names_list:\n",
    "        if are_names_same(name1, name2) and name1 != name2:\n",
    "            mixed_up_names.append([name1, name2])\n",
    "            # avoid inserting the same pair by substituting name1 with name2 in the names list\n",
    "            names_list = np.where(names_list == name1, name2, names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levenshtein distance\n",
    "\n",
    "# create df where rows and columns are the names and the values are the levenshtein distance\n",
    "names_comparison = np.array(np.meshgrid(names, names)).T.reshape(-1,2)\n",
    "\n",
    "# create a third column with the levenshtein distance\n",
    "names_comparison = pd.DataFrame(names_comparison, columns=['name', 'other_names'])\n",
    "names_comparison['levenshtein_distance'] = names_comparison.apply(lambda row: Levenshtein.distance(row['name'], row['other_names']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set thresholds\n",
    "ld1 = names_comparison[names_comparison['levenshtein_distance'] == 1]\n",
    "ld2 = names_comparison[names_comparison['levenshtein_distance'] == 2]\n",
    "ld3 = names_comparison[names_comparison['levenshtein_distance'] == 3]\n",
    "ld4 = names_comparison[names_comparison['levenshtein_distance'] == 4]\n",
    "ld5 = names_comparison[names_comparison['levenshtein_distance'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict with the names that are similar (dont insert same pair twice)\n",
    "similar_names = {}\n",
    "\n",
    "for ld in [ld1, ld2, ld3, ld4, ld5]:\n",
    "    for _, row in ld.iterrows():\n",
    "        # if the name is already in the dict\n",
    "        if row['name'] in similar_names:\n",
    "            # if the other name is not in the list, add it\n",
    "            if row['other_names'] not in similar_names[row['name']]:\n",
    "                similar_names[row['name']].append(row['other_names'])\n",
    "            # if it is, do nothing\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # if the name is not in the dict and the other name is\n",
    "        elif row['other_names'] in similar_names.values():\n",
    "            # if the name isnt on other_name key, add it\n",
    "            if row['name'] not in similar_names[row['other_names']]:\n",
    "                similar_names[row['other_names']].append(row['name'])\n",
    "            # if it is, do nothing\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        # if none of the names are in the dict, add them as a new key\n",
    "        else:\n",
    "            # check which appears the most in the data and add that one as the key\n",
    "            if data[data['Nome Competidor'] == row['name']].shape[0] > data[data['Nome Competidor'] == row['other_names']].shape[0]:\n",
    "                similar_names[row['name']] = [row['other_names']]\n",
    "            else:\n",
    "                similar_names[row['other_names']] = [row['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAN LI LI WAN\n",
      "['LI WAN']\n"
     ]
    }
   ],
   "source": [
    "# if two keys receive True from the are_names_same function, \n",
    "# add the second key and value to the first key's value list and delete the second key\n",
    "\n",
    "# create a list for the keys that will be deleted\n",
    "keys_to_delete = []\n",
    "\n",
    "for key1 in similar_names:\n",
    "    for key2 in similar_names:\n",
    "        # if the keys are the same, skip\n",
    "        if key1 == key2:\n",
    "            pass\n",
    "        elif are_names_same(key1, key2) and (key2 not in keys_to_delete) and (key1 not in keys_to_delete):\n",
    "            print(key1, key2)\n",
    "            # add key2 value to key1 value\n",
    "            similar_names[key1].extend(similar_names[key2])\n",
    "            # add key 2 to key 1 value\n",
    "            similar_names[key1].append(key2)\n",
    "            # add key 2 to keys to delete\n",
    "            keys_to_delete.append(key2)\n",
    "\n",
    "print(keys_to_delete)\n",
    "\n",
    "# delete the keys that are in the keys_to_delete list\n",
    "for key in keys_to_delete:\n",
    "    del similar_names[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sublist in mixed_up_names, check if the mixed_up_names[0] is in similar_names as a key\n",
    "# if it is, add mixed_up_names[1] to the value list\n",
    "\n",
    "for pair in mixed_up_names:\n",
    "    if pair[0] in similar_names:\n",
    "        # append pair[1] to key pair[0]\n",
    "        similar_names[pair[0]].append(pair[1])\n",
    "    elif pair[0] in similar_names.values():\n",
    "        # append pair[1] to the key that has pair[0] as a value\n",
    "        for key in similar_names:\n",
    "            if pair[0] in similar_names[key]:\n",
    "                similar_names[key].append(pair[1])\n",
    "    elif pair[1] in similar_names:\n",
    "        # append pair[0] to key pair[1]\n",
    "        similar_names[pair[1]].append(pair[0])\n",
    "    elif pair[1] in similar_names.values():\n",
    "        # append pair[0] to the key that has pair[1] as a value\n",
    "        for key in similar_names:\n",
    "            if pair[1] in similar_names[key]:\n",
    "                similar_names[key].append(pair[0])\n",
    "    else:\n",
    "        # add pair[0] and pair[1] as a new key and value\n",
    "        similar_names[pair[0]] = [pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LUKAS WALTON-KEIM': ['LUKAS WALTON- KEIM'],\n",
       " 'LUCAS PES FONSECA': ['LUCAS PE FONSECA'],\n",
       " 'SIRIWIT PRANGSRI': ['SIRAWIT PRANGSRI'],\n",
       " 'GEORGE MANEV': ['GEORGI MANEV'],\n",
       " 'MAYA ASHKENAZI': ['MAYA ASSHKENAZI', 'ASHKENAZI MAYA'],\n",
       " 'MARIE-EVE MAYRAND': ['MARIE EVE MAYRAND'],\n",
       " 'JAN VOSTER': ['VOSTER JAN', 'JAN VOESTER'],\n",
       " 'SEBASTIAN KOERDEL': ['SEBASTIAN KORDEL', 'KOERDEL SEBASTIAN'],\n",
       " 'MATTHEW BARTON': ['MATHEW BARTON'],\n",
       " 'RADOSLAW FURMANSKI': ['RADOSLAW FUMANSKI', 'FURMANSKI RADOSLAW'],\n",
       " 'BYRON KOKKALANIS': ['VYRON KOKKALANIS'],\n",
       " 'ANTONINO CANGEMI': ['ANTONIO CANGEMI'],\n",
       " 'FREDERIC RAMSGAARD ORUM': ['FREDERIC RAMSGAARD OERUM'],\n",
       " 'NOCETI-KLEPACKA ZOFIA': ['NOCETI KLEPACKA ZOFIA'],\n",
       " 'LEE TAEHOON': ['LEE TAE HOON', 'TAEHOON LEE'],\n",
       " 'DIMITRI MARAMENIDES': ['DIMITRIS MARAMANIDES'],\n",
       " 'JINGYUE CHEN': ['JINGLE CHEN', 'CHEN JINGYUE'],\n",
       " 'WAN LI': ['WANG SI', 'BI KUN', 'KUN BI', 'LI WAN'],\n",
       " 'SI WANG': ['WANG SI', 'LI WAN'],\n",
       " 'TUVA OPPEDAL': ['THEA OPPEDAL'],\n",
       " 'JOSH ARMIT': ['JOSHUA ARMIT'],\n",
       " 'MARTINS DZIRNIEKS': ['MARTINS DZINRIEKS'],\n",
       " 'HARRY JOYNER': ['HARRY H JOYNER', 'JOYNER HARRY'],\n",
       " 'MAX NOCHER': ['MAXIME NOCHER'],\n",
       " 'BRUNO LOBO': ['LOBO BRUNO', 'BRUNO LIMA'],\n",
       " 'MARTIN DOLENC': ['MARIJA DOLENC', 'DOLENC MARTIN'],\n",
       " 'NICOLAS PARLIER': ['PARLIER NICOLAS', 'NICO PARLIER'],\n",
       " 'KARL MAEDER': ['MAEDER KARL', 'MAX MAEDER'],\n",
       " 'MAYA MORRIS': ['MAC MORRIN'],\n",
       " 'VOJTECH KOSKA': ['VOJTA KOSKA', 'KOSKA VOJTECH'],\n",
       " 'ANDERS BECKETT': ['ALBERT BECKETT'],\n",
       " 'ASGER BECKETT': ['ALBERT BECKETT'],\n",
       " 'DANIEL SELF': ['DANIEL LEOW', 'SELF DANIEL'],\n",
       " 'JANE TAYLOR': ['JOEY TAYLOR', 'TAYLOR JANE'],\n",
       " 'MARTIN PARIENTE': ['ANTON PARIENTE'],\n",
       " 'MAX CASTELEIN': ['MANON CASTELEIN'],\n",
       " 'WILL MCMILLAN': ['WILLIAM MCMILLAN', 'MCMILLAN WILL'],\n",
       " 'LUCAS PE FONSECA': ['LUCAS FONSECA'],\n",
       " 'ANDY BROWN': ['ANDREW BROWN'],\n",
       " 'NICOLO RENNA': ['JACOPO RENNA'],\n",
       " 'SAMUEL SILLS': ['SAM SILLS'],\n",
       " 'YOAV OMER': ['YOAV COHEN'],\n",
       " 'YUN POULIQUEN': ['OEL POULIQUEN'],\n",
       " 'STEPHEN ALLEN': ['STEVE ALLEN'],\n",
       " 'KUN BI': ['WAN LI', 'BI KUN'],\n",
       " 'ELI LIEFTING': ['ELIJAH LIEFTING'],\n",
       " 'BAZ BEL': ['PAZ YAEL'],\n",
       " 'DOLENC MARIJA': ['MARIJA DOLENC', 'DOLENC MARTIN'],\n",
       " 'MAXIMILIAN MAEDER': ['MAEDER MAXIMILIAN'],\n",
       " 'TONI VODISEK': ['VODISEK TONI'],\n",
       " 'RICCARDO PIANOSI': ['PIANOSI RICCARDO'],\n",
       " 'BENOIT GOMEZ': ['GOMEZ BENOIT'],\n",
       " 'LORENZO BOSCHETTI': ['BOSCHETTI LORENZO'],\n",
       " 'MARKUS EDEGRAN': ['EDEGRAN MARKUS'],\n",
       " 'JANNIS MAUS': ['MAUS JANNIS'],\n",
       " 'MAKSYMILIAN ZAKOWSKI': ['ZAKOWSKI MAKSYMILIAN'],\n",
       " 'FLORIAN GRUBER': ['GRUBER FLORIAN'],\n",
       " 'JAN MARCINIAK': ['MARCINIAK JAN'],\n",
       " 'ALEXANDER EHLEN': ['EHLEN ALEXANDER'],\n",
       " 'DVIR AZULAY': ['AZULAY DVIR'],\n",
       " 'VALENTIN BONTUS': ['BONTUS VALENTIN'],\n",
       " 'ALEJANDRO CLIMENT HERNANDEZ': ['CLIMENT HERNANDEZ ALEJANDRO'],\n",
       " 'ALESSIO BRASILI': ['BRASILI ALESSIO'],\n",
       " 'NOAH RUNCIMAN': ['RUNCIMAN NOAH'],\n",
       " 'ARTHUR LHEZ': ['LHEZ ARTHUR'],\n",
       " 'THEO DE RAMECOURT': ['DE RAMECOURT THEO'],\n",
       " 'TIGER TYSON': ['TYSON TIGER'],\n",
       " 'ZOHAR HARUVI': ['HARUVI ZOHAR'],\n",
       " 'HAORAN ZHANG': ['ZHANG HAORAN'],\n",
       " 'BRUCE KESSLER': ['KESSLER BRUCE'],\n",
       " 'MICHAL WOJCIECHOWSKI': ['WOJCIECHOWSKI MICHAL'],\n",
       " 'BERNAT CORTES': ['CORTES BERNAT'],\n",
       " 'YAEL PAZ': ['PAZ YAEL'],\n",
       " 'JAKUB JURKOWSKI': ['JURKOWSKI JAKUB'],\n",
       " 'EJDER GINYOL': ['GINYOL EJDER'],\n",
       " 'JACOBO ESPI VANO': ['ESPI VANO JACOBO'],\n",
       " 'DOR ZARKA': ['ZARKA DOR'],\n",
       " 'AXEL MAZELLA': ['MAZELLA AXEL'],\n",
       " 'SIRAWIT PRANGSRI': ['PRANGSRI SIRAWIT'],\n",
       " 'MARCIN KROCZAK': ['KROCZAK MARCIN'],\n",
       " 'ANDRE OLSSON': ['OLSSON ANDRE'],\n",
       " 'PO CHAK LEUNG': ['LEUNG PO CHAK'],\n",
       " 'MARIO CALBUCCI': ['CALBUCCI MARIO'],\n",
       " 'LAURIANE NOLOT': ['NOLOT LAURIANE'],\n",
       " 'JESSIE KAMPMAN': ['KAMPMAN JESSIE'],\n",
       " 'GAL ZUKERMAN': ['ZUKERMAN GAL'],\n",
       " 'GISELA PULIDO BORRELL': ['PULIDO BORRELL GISELA'],\n",
       " 'IZABELA SATRJAN': ['SATRJAN IZABELA'],\n",
       " 'BREIANA WHITEHEAD': ['WHITEHEAD BREIANA'],\n",
       " 'POEMA NEWLAND': ['NEWLAND POEMA'],\n",
       " 'MAGDALENA WOYCIECHOWSKA': ['WOYCIECHOWSKA MAGDALENA'],\n",
       " 'ALEXIA FANCELLI': ['FANCELLI ALEXIA'],\n",
       " 'JULIA DAMASIEWICZ': ['DAMASIEWICZ JULIA'],\n",
       " 'ALINA KORNELLI': ['KORNELLI ALINA'],\n",
       " 'NINA ARCISZ': ['ARCISZ NINA'],\n",
       " 'SOFIA TOMASONI': ['TOMASONI SOFIA'],\n",
       " 'ANAIS MAI DESJARDINS': ['DESJARDINS ANAIS MAI'],\n",
       " 'HELOISE PEGOURIE': ['PEGOURIE HELOISE'],\n",
       " 'LYSA CAVAL': ['CAVAL LYSA'],\n",
       " 'CHLOE REVIL': ['REVIL CHLOE'],\n",
       " 'DERIN ATAKAN': ['ATAKAN DERIN'],\n",
       " 'TIANA LAPORTE': ['LAPORTE TIANA'],\n",
       " 'ZOE BOUTANG': ['BOUTANG ZOE'],\n",
       " 'BENYAPA JANTAWAN': ['JANTAWAN BENYAPA'],\n",
       " 'KAROLINA LARSSON': ['LARSSON KAROLINA'],\n",
       " 'MONIKA ZIZLAVSKA': ['ZIZLAVSKA MONIKA'],\n",
       " 'MAXIME NOCHER': ['NOCHER MAXIME'],\n",
       " 'GUY BRIDGE': ['BRIDGE GUY'],\n",
       " 'CONNOR BAINBRIDGE': ['BAINBRIDGE CONNOR'],\n",
       " 'BLAZEJ OZOG': ['OZOG BLAZEJ'],\n",
       " 'ANTHONY PICARD': ['PICARD ANTHONY'],\n",
       " 'ULYSSE DEREEPER': ['DEREEPER ULYSSE'],\n",
       " 'XANTOS VILLEGAS': ['VILLEGAS XANTOS'],\n",
       " 'MALO QUERNEC': ['QUERNEC MALO'],\n",
       " 'ENZO PEREZ': ['PEREZ ENZO'],\n",
       " 'JINDRICH HOUSTEK': ['HOUSTEK JINDRICH'],\n",
       " 'MARIUS DE MOURGUES': ['DE MOURGUES MARIUS'],\n",
       " 'PIOTR SZYMIEC': ['SZYMIEC PIOTR'],\n",
       " 'JEAN ROMAIN MOREL': ['MOREL JEAN ROMAIN'],\n",
       " 'MATTHIEU IZARD': ['IZARD MATTHIEU'],\n",
       " 'OSCAR BARBERA FERRAGUD': ['BARBERA FERRAGUD OSCAR'],\n",
       " 'DANIELA MOROZ': ['MOROZ DANIELA'],\n",
       " 'ELLIE ALDRIDGE': ['ALDRIDGE ELLIE'],\n",
       " 'KATIE DABSON': ['DABSON KATIE'],\n",
       " 'MAGGIE PESCETTO': ['PESCETTO MAGGIE'],\n",
       " 'LEONIE MEYER': ['MEYER LEONIE'],\n",
       " 'JEMIMA CRATHORNE': ['CRATHORNE JEMIMA'],\n",
       " 'DOMINIKA SAWICKA': ['SAWICKA DOMINIKA'],\n",
       " 'NINA BIVAUD': ['BIVAUD NINA'],\n",
       " 'DERIN DENIZ SORGUC': ['SORGUC DERIN DENIZ'],\n",
       " 'HELENE NOESMOEN': ['NOESMOEN HELENE'],\n",
       " 'EMMA WILSON': ['WILSON EMMA'],\n",
       " 'MAJA DZIARNOWSKA': ['DZIARNOWSKA MAJA'],\n",
       " 'MARTA MAGGETTI': ['MAGGETTI MARTA'],\n",
       " 'VEERLE TEN HAVE': ['TEN HAVE VEERLE'],\n",
       " 'DELPHINE COUSIN': ['COUSIN DELPHINE'],\n",
       " 'LUCIE BELBEOCH': ['BELBEOCH LUCIE'],\n",
       " 'GIORGIA SPECIALE': ['SPECIALE GIORGIA'],\n",
       " 'LOLA SORIN': ['SORIN LOLA'],\n",
       " 'MAJA KUCHTA': ['KUCHTA MAJA'],\n",
       " 'SASKIA SILLS': ['SILLS SASKIA'],\n",
       " 'MANON PIANAZZA': ['PIANAZZA MANON'],\n",
       " 'KWAN CHING MA': ['MA KWAN CHING'],\n",
       " 'MARION COUTURIER': ['COUTURIER MARION'],\n",
       " 'MARION MORTEFON': ['MORTEFON MARION'],\n",
       " 'AMBAR PAPAZIAN': ['PAPAZIAN AMBAR'],\n",
       " 'ZOFIA NOCETI KLEPACKA': ['NOCETI KLEPACKA ZOFIA'],\n",
       " 'KATY SPYCHAKOV': ['SPYCHAKOV KATY'],\n",
       " 'SOFIA RENNA': ['RENNA SOFIA'],\n",
       " 'LENA ERDIL': ['ERDIL LENA'],\n",
       " 'NATASHA BRYANT': ['BRYANT NATASHA'],\n",
       " 'RINA NIIJIMA': ['NIIJIMA RINA'],\n",
       " 'ALISA ENGELMANN': ['ENGELMANN ALISA'],\n",
       " 'ONISHI FUJIKO': ['FUJIKO ONISHI'],\n",
       " 'SAMANTHA COSTIN': ['COSTIN SAMANTHA'],\n",
       " 'BRIANNA ORAMS': ['ORAMS BRIANNA'],\n",
       " 'SUNAGA YUKI': ['YUKI SUNAGA'],\n",
       " 'JOHANNA HJERTBERG': ['HJERTBERG JOHANNA'],\n",
       " 'LINDA OPRANDI': ['OPRANDI LINDA'],\n",
       " 'MANON BERGER': ['BERGER MANON'],\n",
       " 'FARRAH HALL': ['HALL FARRAH'],\n",
       " 'JUNNA WATANABE': ['WATANABE JUNNA'],\n",
       " 'MIKI YAMABE': ['YAMABE MIKI'],\n",
       " 'GOMEZ ROA JULIA': ['JULIA GOMEZ ROA'],\n",
       " 'SZENTIVANYI SARA': ['SARA SZENTIVANYI'],\n",
       " 'LILY YOUNG': ['YOUNG LILY'],\n",
       " 'LILOU BALANCA': ['BALANCA LILOU'],\n",
       " 'KIMBERLEY RIJSBERGEN': ['RIJSBERGEN KIMBERLEY'],\n",
       " 'FABIEN PIANAZZA': ['PIANAZZA FABIEN'],\n",
       " 'ONUR CAVIT BIRIZ': ['BIRIZ ONUR CAVIT'],\n",
       " 'KENSEI IKEDA': ['IKEDA KENSEI'],\n",
       " 'MATHIS ALEXIS': ['ALEXIS MATHIS'],\n",
       " 'ROMAIN GHIO': ['GHIO ROMAIN'],\n",
       " 'JULES CHANTREL': ['CHANTREL JULES'],\n",
       " 'ANAMI TOMONORI': ['TOMONORI ANAMI'],\n",
       " 'DAIYA KURAMOCHI': ['KURAMOCHI DAIYA'],\n",
       " 'XIALING TAN': ['TAN XIALING'],\n",
       " 'XIANTING HUANG': ['HUANG XIANTING'],\n",
       " 'MANJIA ZHENG': ['ZHENG MANJIA'],\n",
       " 'ZHENG YAN': ['YAN ZHENG'],\n",
       " 'JIE DU': ['DU JIE'],\n",
       " 'YUNXIU LU': ['LU YUNXIU'],\n",
       " 'BRUNA MARTINELLI': ['MARTINELLI BRUNA'],\n",
       " 'QIBIN HUANG': ['HUANG QIBIN'],\n",
       " 'GIAN ANDREA STRAGIOTTI': ['STRAGIOTTI GIAN ANDREA'],\n",
       " 'PAUL LABORDERE': ['LABORDERE PAUL'],\n",
       " 'ANIL GARNIER': ['GARNIER ANIL'],\n",
       " 'MATHEO COGUIEC': ['COGUIEC MATHEO'],\n",
       " 'TITOUAN CHINOT': ['CHINOT TITOUAN'],\n",
       " 'NELL DE JAHAM': ['DE JAHAM NELL'],\n",
       " 'CLEMENT BOURGEOIS': ['BOURGEOIS CLEMENT'],\n",
       " 'LOUIS PIGNOLET': ['PIGNOLET LOUIS'],\n",
       " 'THOMAS GOYARD': ['GOYARD THOMAS'],\n",
       " 'TITOUAN LE BOSQ': ['LE BOSQ TITOUAN'],\n",
       " 'PIERRE LE COQ': ['LE COQ PIERRE'],\n",
       " 'TOM ARNOUX': ['ARNOUX TOM'],\n",
       " 'RYTIS JASIUNAS': ['JASIUNAS RYTIS'],\n",
       " 'GASPARD CARFANTAN': ['CARFANTAN GASPARD'],\n",
       " 'TOMAS VIEITO COBIAN': ['VIEITO COBIAN TOMAS'],\n",
       " 'ADRIEN MESTRE': ['MESTRE ADRIEN'],\n",
       " 'OEL POULIQUEN': ['POULIQUEN OEL'],\n",
       " 'KAMIL MANOWIECKI': ['MANOWIECKI KAMIL'],\n",
       " 'JONNE HEIMANN': ['HEIMANN JONNE'],\n",
       " 'CHING YIN CHENG': ['CHENG CHING YIN'],\n",
       " 'DOMINIK LEWINSKI': ['LEWINSKI DOMINIK'],\n",
       " 'BENOIT MERCEUR': ['MERCEUR BENOIT'],\n",
       " 'MINHAI YANG': ['YANG MINHAI'],\n",
       " 'LING YEUNG AU': ['AU LING YEUNG'],\n",
       " 'SEBASTIAN SCHARER': ['SCHARER SEBASTIAN'],\n",
       " 'GRAE MORRIS': ['MORRIS GRAE'],\n",
       " 'MAKOTO TOMIZAWA': ['TOMIZAWA MAKOTO'],\n",
       " 'CAELIN WINCHCOMBE': ['WINCHCOMBE CAELIN'],\n",
       " 'MATTEO BENZ': ['BENZ MATTEO'],\n",
       " 'ROBERT KUBIN': ['KUBIN ROBERT'],\n",
       " 'TOMAS BERNAT': ['BERNAT TOMAS'],\n",
       " 'RAFEEK KIKABHOY': ['KIKABHOY RAFEEK'],\n",
       " 'PIOTR MYSZKA': ['MYSZKA PIOTR'],\n",
       " 'NICOLAS GOYARD': ['GOYARD NICOLAS'],\n",
       " 'FABIAN WOLF': ['WOLF FABIAN'],\n",
       " 'LARS POGGEMANN': ['POGGEMANN LARS'],\n",
       " 'ELKAN OH': ['OH ELKAN'],\n",
       " 'OLEKSANDR TUGARYEV': ['TUGARYEV OLEKSANDR'],\n",
       " 'CLEMENT DESTOMBES': ['DESTOMBES CLEMENT'],\n",
       " 'JIANG QIANFAN': ['QIANFAN JIANG'],\n",
       " 'JOSHUA ARMIT': ['ARMIT JOSHUA'],\n",
       " 'THOMAS CROOK': ['CROOK THOMAS'],\n",
       " 'MICHAL POLAK': ['POLAK MICHAL'],\n",
       " 'JINGYE HUANG': ['HUANG JINGYE'],\n",
       " 'CHANEUI KIM': ['KIM CHANEUI'],\n",
       " 'MEHDI GUEMBRI': ['GUEMBRI MEHDI'],\n",
       " 'KOMINE MEGUMI': ['MEGUMI KOMINE'],\n",
       " 'HIRO KARAMON': ['KARAMON HIRO'],\n",
       " 'ALEXANDRE COUSIN': ['COUSIN ALEXANDRE'],\n",
       " 'HYEONGJUNG KANG': ['KANG HYEONGJUNG'],\n",
       " 'SACHIN GANESH': ['GANESH SACHIN'],\n",
       " 'ELIJAH LIEFTING': ['LIEFTING ELIJAH'],\n",
       " 'SARUN RUPCHOM': ['RUPCHOM SARUN'],\n",
       " 'JOSEPH JONATHAN WESTON': ['WESTON JOSEPH JONATHAN'],\n",
       " 'MADELEINE ANDERSON': ['ANDERSON MADELEINE']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a key has repeated values, delete one of them\n",
    "for key in similar_names:\n",
    "    similar_names[key] = list(set(similar_names[key]))\n",
    "similar_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder similar_names dict by alphabetical order of the keys\n",
    "similar_names = dict(sorted(similar_names.items(), key=lambda item: item[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output similar_names to json\n",
    "import json\n",
    "\n",
    "with open('similar_names_ld.json', 'w') as fp:\n",
    "    json.dump(similar_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json to dict\n",
    "with open('similar_names_ld.json', 'r') as fp:\n",
    "    similar_names_dict = json.load(fp)\n",
    "\n",
    "# for each key, substitute the values by the key in the data\n",
    "for key in similar_names_dict:\n",
    "    for value in similar_names_dict[key]:\n",
    "        data['Nome Competidor'] = np.where(data['Nome Competidor'] == value, key, data['Nome Competidor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Resultado</th>\n",
       "      <th>ID Competidor</th>\n",
       "      <th>Nome Competidor</th>\n",
       "      <th>ID Competição</th>\n",
       "      <th>Classe Vela</th>\n",
       "      <th>Pontuação Regata</th>\n",
       "      <th>Descarte</th>\n",
       "      <th>Flotilha</th>\n",
       "      <th>Posição Geral</th>\n",
       "      <th>Punição</th>\n",
       "      <th>Pontuação Total</th>\n",
       "      <th>Nett</th>\n",
       "      <th>Nome Competição</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID Resultado, ID Competidor, Nome Competidor, ID Competição, Classe Vela, Pontuação Regata, Descarte, Flotilha, Posição Geral, Punição, Pontuação Total, Nett, Nome Competição]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show data where Nome Competidor is MAXIME NOCHER\n",
    "data[data['Nome Competidor'] == 'MAX NOCHER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
