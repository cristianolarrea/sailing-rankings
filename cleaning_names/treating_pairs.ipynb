{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carol Erthal\\AppData\\Local\\Temp\\ipykernel_4000\\3196152256.py:8: DtypeWarning: Columns (8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('../data/Banco de Súmulas - Sumulas.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "import re\n",
    "import unidecode\n",
    "import json\n",
    "\n",
    "data = pd.read_csv('../data/Banco de Súmulas - Sumulas.csv')\n",
    "\n",
    "# keep only pair classes\n",
    "classes = ['470', '49er', '49erFX', 'Nacra 17']\n",
    "data = data[data['Classe Vela'].isin(classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carol Erthal\\AppData\\Local\\Temp\\ipykernel_4000\\3585964946.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['Nome Competidor'] = data['Nome Competidor'].str.replace(r'\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "# treating strings\n",
    "\n",
    "# unidecode\n",
    "data['Nome Competidor'] = data['Nome Competidor'].apply(unidecode.unidecode)\n",
    "\n",
    "# replace more than one space by one space\n",
    "data['Nome Competidor'] = data['Nome Competidor'].str.replace(r'\\s+', ' ')\n",
    "\n",
    "# substituir [;] por [virgula espaço]\n",
    "data['Nome Competidor'] = data['Nome Competidor'].str.replace(r';', r', ')\n",
    "\n",
    "# substituir [ / ] por [virgula espaço]\n",
    "data['Nome Competidor'] = data['Nome Competidor'].str.replace(r' / ', r', ')\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if re.match(r'^([A-Z]{2,})', row['Nome Competidor']):\n",
    "        # ERTHAL Carol LAMARCA Felipe\n",
    "        data.at[index, \"Nome Competidor\"] = re.sub(r'([a-z]{2,}) ([A-Z]{2,})', r'\\1, \\2', data.at[index, \"Nome Competidor\"])\n",
    "                \n",
    "        # ERTHAL CarolLAMARCA Felipe\n",
    "        data.at[index, \"Nome Competidor\"] = re.sub(r'([a-z]{2,})([A-Z]{2,})', r'\\1, \\2', data.at[index, \"Nome Competidor\"])\n",
    "\n",
    "    else:\n",
    "        # Carol ERTHALFelipe LAMARCA\n",
    "        data.at[index, \"Nome Competidor\"] = re.sub(r'([A-Z])([A-Z][a-z])', r'\\1, \\2', data.at[index, \"Nome Competidor\"])\n",
    "\n",
    "        # Carol ERTHAL Felipe LAMARCA\n",
    "        data.at[index, \"Nome Competidor\"] = re.sub(r'([A-Z]) ([A-Z][a-z])', r'\\1, \\2', data.at[index, \"Nome Competidor\"])\n",
    "\n",
    "        # Carol ErthalFelipe Lamarca / Erthal CarolLamarca Felipe\n",
    "        data.at[index, \"Nome Competidor\"] = re.sub(r'([a-z])([A-Z][a-z])', r'\\1, \\2', data.at[index, \"Nome Competidor\"])\n",
    "\n",
    "# upper case\n",
    "data['Nome Competidor'] = data['Nome Competidor'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(data['Nome Competidor'].unique())\n",
    "\n",
    "to_fix_manually = {}\n",
    "for name in unique:\n",
    "    # se tiver mais de uma virgula, adicionar como chave no dicionario\n",
    "    if len(re.findall(r',', name)) > 1:\n",
    "        to_fix_manually[name] = []\n",
    "    # se nao tiver virgula, adicionar como chave no dicionario\n",
    "    elif len(re.findall(r',', name)) == 0:\n",
    "        to_fix_manually[name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_fix_manually to json\n",
    "with open('../data/to_fix_manually.json', 'w') as fp:\n",
    "    json.dump(to_fix_manually, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'manual_fix.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Carol Erthal\\Documents\\fgv\\6P\\FIELDS\\sailing-rankings\\cleaning_names\\treating_pairs.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/6P/FIELDS/sailing-rankings/cleaning_names/treating_pairs.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# fix manually the ones found above\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/6P/FIELDS/sailing-rankings/cleaning_names/treating_pairs.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/6P/FIELDS/sailing-rankings/cleaning_names/treating_pairs.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# read json file as dict\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/6P/FIELDS/sailing-rankings/cleaning_names/treating_pairs.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mmanual_fix.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/6P/FIELDS/sailing-rankings/cleaning_names/treating_pairs.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     manual_fix \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/6P/FIELDS/sailing-rankings/cleaning_names/treating_pairs.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# replace keys by values in data using manual_fix\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'manual_fix.json'"
     ]
    }
   ],
   "source": [
    "# # fix manually the ones found above\n",
    "\n",
    "# # read json file as dict\n",
    "# with open('manual_fix.json', 'r') as f:\n",
    "#     manual_fix = json.load(f)\n",
    "\n",
    "# # replace keys by values in data using manual_fix\n",
    "# for key, value in manual_fix.items():\n",
    "#     data['Nome Competidor'] = data['Nome Competidor'].str.replace(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique names again\n",
    "unique = list(data['Nome Competidor'].unique())\n",
    "\n",
    "# fix mixed up names function\n",
    "def are_names_same(str1, str2):\n",
    "    # Split the strings into words, remove spaces, and sort the lists of words\n",
    "    name1 = sorted(str1.split())\n",
    "    name2 = sorted(str2.split())\n",
    "    \n",
    "    # Check if the sorted lists of words are equal\n",
    "    return name1 == name2\n",
    "\n",
    "# get pairs\n",
    "pairs = []\n",
    "for i in range(len(unique)):\n",
    "    for j in range(i+1, len(unique)):\n",
    "        if are_names_same(unique[i], unique[j]):\n",
    "            pairs.append((unique[i], unique[j]))\n",
    "\n",
    "# substitute pairs in data\n",
    "for pair in pairs:\n",
    "    data['Nome Competidor'] = data['Nome Competidor'].str.replace(pair[1], pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data['Nome Competidor'].unique()\n",
    "# levenshtein distance\n",
    "\n",
    "# create df where rows and columns are the names and the values are the levenshtein distance\n",
    "names_comparison = np.array(np.meshgrid(names, names)).T.reshape(-1,2)\n",
    "\n",
    "# create a third column with the levenshtein distance\n",
    "names_comparison = pd.DataFrame(names_comparison, columns=['name', 'other_names'])\n",
    "names_comparison['levenshtein_distance'] = names_comparison.apply(lambda row: Levenshtein.distance(row['name'], row['other_names']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld1 = names_comparison[names_comparison['levenshtein_distance'] == 1]\n",
    "ld2 = names_comparison[names_comparison['levenshtein_distance'] == 2]\n",
    "ld3 = names_comparison[names_comparison['levenshtein_distance'] == 3]\n",
    "ld4 = names_comparison[names_comparison['levenshtein_distance'] == 4]\n",
    "ld5 = names_comparison[names_comparison['levenshtein_distance'] == 5]\n",
    "ld6 = names_comparison[names_comparison['levenshtein_distance'] == 6]\n",
    "ld7 = names_comparison[names_comparison['levenshtein_distance'] == 7]\n",
    "ld8 = names_comparison[names_comparison['levenshtein_distance'] == 8]\n",
    "ld9 = names_comparison[names_comparison['levenshtein_distance'] == 9]\n",
    "ld10 = names_comparison[names_comparison['levenshtein_distance'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict with the names that are similar (dont insert same pair twice)\n",
    "similar_names = {}\n",
    "\n",
    "for ld in [ld1, ld2, ld3, ld4, ld5, ld6, ld7, ld8, ld9, ld10]:\n",
    "    for _, row in ld.iterrows():\n",
    "        # if the name is already in the dict\n",
    "        if row['name'] in similar_names:\n",
    "            # if the other name is not in the list, add it\n",
    "            if row['other_names'] not in similar_names[row['name']]:\n",
    "                similar_names[row['name']].append(row['other_names'])\n",
    "            # if it is, do nothing\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # if the name is not in the dict and the other name is\n",
    "        elif row['other_names'] in similar_names.values():\n",
    "            # if the name isnt on other_name key, add it\n",
    "            if row['name'] not in similar_names[row['other_names']]:\n",
    "                similar_names[row['other_names']].append(row['name'])\n",
    "            # if it is, do nothing\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        # if none of the names are in the dict, add them as a new key\n",
    "        else:\n",
    "            # check which appears the most in the data and add that one as the key\n",
    "            if data[data['Nome Competidor'] == row['name']].shape[0] > data[data['Nome Competidor'] == row['other_names']].shape[0]:\n",
    "                similar_names[row['name']] = [row['other_names']]\n",
    "            else:\n",
    "                similar_names[row['other_names']] = [row['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every unique name not in the dict as key or value, add it as a key with an empty list as value\n",
    "for name in names:\n",
    "    if name not in similar_names and name not in similar_names.values():\n",
    "        similar_names[name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenar similar_names por ordem alfabetica das chaves\n",
    "similar_names = {k: v for k, v in sorted(similar_names.items(), key=lambda item: item[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar_names to json\n",
    "with open('../data/similar_names.json', 'w') as fp:\n",
    "    json.dump(similar_names, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
